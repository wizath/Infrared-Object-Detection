{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# YOLO11 Training Notebook\n",
        "\n",
        "This notebook provides a comprehensive interface for training YOLO11 models on custom datasets.\n",
        "Based on the infrared object detection dataset for person, bicycle, and car detection.\n",
        "\n",
        "## Features\n",
        "- Model training with customizable parameters\n",
        "- Real-time training monitoring\n",
        "- Model validation and testing\n",
        "- Results visualization\n",
        "- Model export capabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Image, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Import YOLO11\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Configuration Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Project configuration\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "DATA_CONFIG = PROJECT_ROOT / 'data_infrared.yaml'\n",
        "WEIGHTS_PATH = PROJECT_ROOT / 'yolo11n.pt'\n",
        "RUNS_DIR = PROJECT_ROOT / 'runs' / 'train'\n",
        "\n",
        "# Training configuration\n",
        "TRAINING_CONFIG = {\n",
        "    'model_size': 'yolo11n.pt',  # yolo11n, yolo11s, yolo11m, yolo11l, yolo11x\n",
        "    'epochs': 100,\n",
        "    'batch_size': 16,\n",
        "    'img_size': 640,\n",
        "    'workers': 8,\n",
        "    'device': '',  # '' for auto, '0' for GPU 0, 'cpu' for CPU\n",
        "    'project': 'runs/train',\n",
        "    'name': 'yolo11_infrared',\n",
        "    'patience': 50,\n",
        "    'save_period': 10,\n",
        "    'cache': 'ram',  # 'ram', 'disk', or False\n",
        "    'amp': True,  # Automatic Mixed Precision\n",
        "    'optimizer': 'auto',  # 'SGD', 'Adam', 'AdamW', 'auto'\n",
        "    'lr0': 0.01,\n",
        "    'lrf': 0.01,\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'cos_lr': False,\n",
        "    'rect': False,\n",
        "    'resume': False\n",
        "}\n",
        "\n",
        "print(\"Configuration loaded:\")\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Dataset Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display dataset configuration\n",
        "def load_dataset_config(config_path):\n",
        "    \"\"\"Load dataset configuration from YAML file.\"\"\"\n",
        "    with open(config_path, 'r') as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "def display_dataset_info(config):\n",
        "    \"\"\"Display dataset information.\"\"\"\n",
        "    print(\"Dataset Configuration:\")\n",
        "    print(f\"  Path: {config['path']}\")\n",
        "    print(f\"  Classes: {config['nc']}\")\n",
        "    print(f\"  Class names: {config['names']}\")\n",
        "    print(f\"  Train: {config['train']}\")\n",
        "    print(f\"  Validation: {config['val']}\")\n",
        "    \n",
        "    # Check dataset statistics\n",
        "    dataset_path = Path(config['path'])\n",
        "    if dataset_path.exists():\n",
        "        train_images = list((dataset_path / config['train']).glob('*.jpg'))\n",
        "        val_images = list((dataset_path / config['val']).glob('*.jpg'))\n",
        "        \n",
        "        print(f\"\\nDataset Statistics:\")\n",
        "        print(f\"  Training images: {len(train_images)}\")\n",
        "        print(f\"  Validation images: {len(val_images)}\")\n",
        "        print(f\"  Total images: {len(train_images) + len(val_images)}\")\n",
        "    else:\n",
        "        print(f\"\\nWarning: Dataset path {dataset_path} does not exist!\")\n",
        "\n",
        "# Load and display dataset info\n",
        "if DATA_CONFIG.exists():\n",
        "    dataset_config = load_dataset_config(DATA_CONFIG)\n",
        "    display_dataset_info(dataset_config)\n",
        "else:\n",
        "    print(f\"Warning: Dataset config file {DATA_CONFIG} not found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Model Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model(weights_path, verbose=True):\n",
        "    \"\"\"Load YOLO11 model.\"\"\"\n",
        "    try:\n",
        "        model = YOLO(weights_path)\n",
        "        if verbose:\n",
        "            print(f\"Model loaded successfully: {weights_path}\")\n",
        "            print(f\"Model architecture: {model.model}\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load the model\n",
        "print(f\"Loading model: {TRAINING_CONFIG['model_size']}\")\n",
        "model = load_model(TRAINING_CONFIG['model_size'])\n",
        "\n",
        "if model:\n",
        "    print(\"\\nModel summary:\")\n",
        "    try:\n",
        "        model.info()\n",
        "    except:\n",
        "        print(\"Model info not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Interactive Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive training configuration widgets\n",
        "epochs_widget = widgets.IntSlider(value=100, min=1, max=500, description='Epochs:')\n",
        "batch_size_widget = widgets.IntSlider(value=16, min=1, max=64, description='Batch Size:')\n",
        "img_size_widget = widgets.Dropdown(options=[320, 416, 512, 640, 832, 1024], value=640, description='Image Size:')\n",
        "model_widget = widgets.Dropdown(options=['yolo11n.pt', 'yolo11s.pt', 'yolo11m.pt', 'yolo11l.pt', 'yolo11x.pt'], \n",
        "                               value='yolo11n.pt', description='Model:')\n",
        "optimizer_widget = widgets.Dropdown(options=['auto', 'SGD', 'Adam', 'AdamW'], value='auto', description='Optimizer:')\n",
        "device_widget = widgets.Dropdown(options=['auto', '0', 'cpu'], value='auto', description='Device:')\n",
        "patience_widget = widgets.IntSlider(value=50, min=10, max=200, description='Patience:')\n",
        "lr0_widget = widgets.FloatLogSlider(value=0.01, base=10, min=-4, max=-1, description='Learning Rate:')\n",
        "\n",
        "# Display widgets\n",
        "config_box = widgets.VBox([\n",
        "    widgets.HTML(\"<h3>Training Configuration</h3>\"),\n",
        "    epochs_widget,\n",
        "    batch_size_widget,\n",
        "    img_size_widget,\n",
        "    model_widget,\n",
        "    optimizer_widget,\n",
        "    device_widget,\n",
        "    patience_widget,\n",
        "    lr0_widget\n",
        "])\n",
        "\n",
        "display(config_box)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Training Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_training_logging(log_dir):\n",
        "    \"\"\"Setup logging for training.\"\"\"\n",
        "    log_dir = Path(log_dir)\n",
        "    log_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    log_file = log_dir / f'training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
        "    \n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file),\n",
        "            logging.StreamHandler()\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return logging.getLogger('YOLO11_TRAIN'), log_file\n",
        "\n",
        "def train_model(model, config, data_config_path, log_progress=True):\n",
        "    \"\"\"Train YOLO11 model with given configuration.\"\"\"\n",
        "    \n",
        "    # Setup logging\n",
        "    log_dir = Path(config['project']) / config['name']\n",
        "    logger, log_file = setup_training_logging(log_dir)\n",
        "    \n",
        "    logger.info(\"Starting YOLO11 training...\")\n",
        "    logger.info(f\"Configuration: {config}\")\n",
        "    \n",
        "    # Prepare training arguments\n",
        "    train_args = {\n",
        "        'data': str(data_config_path),\n",
        "        'epochs': config['epochs'],\n",
        "        'batch': config['batch_size'],\n",
        "        'imgsz': config['img_size'],\n",
        "        'device': config['device'] if config['device'] != 'auto' else '',\n",
        "        'workers': config['workers'],\n",
        "        'project': config['project'],\n",
        "        'name': config['name'],\n",
        "        'exist_ok': True,\n",
        "        'pretrained': True,\n",
        "        'optimizer': config['optimizer'],\n",
        "        'patience': config['patience'],\n",
        "        'save_period': config['save_period'],\n",
        "        'cache': config['cache'],\n",
        "        'amp': config['amp'],\n",
        "        'lr0': config['lr0'],\n",
        "        'lrf': config['lrf'],\n",
        "        'momentum': config['momentum'],\n",
        "        'weight_decay': config['weight_decay'],\n",
        "        'cos_lr': config['cos_lr'],\n",
        "        'rect': config['rect'],\n",
        "        'resume': config['resume'],\n",
        "        'plots': True,\n",
        "        'verbose': True\n",
        "    }\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Start training\n",
        "        results = model.train(**train_args)\n",
        "        \n",
        "        # Calculate training time\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        hours = int(training_time // 3600)\n",
        "        minutes = int((training_time % 3600) // 60)\n",
        "        seconds = int(training_time % 60)\n",
        "        \n",
        "        logger.info(f\"Training completed successfully!\")\n",
        "        logger.info(f\"Training time: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
        "        logger.info(f\"Log file: {log_file}\")\n",
        "        \n",
        "        return results, log_file\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"Training interrupted by user\")\n",
        "        return None, log_file\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Training failed: {e}\")\n",
        "        raise e\n",
        "\n",
        "print(\"Training functions defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Start Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update configuration from widgets\n",
        "TRAINING_CONFIG.update({\n",
        "    'epochs': epochs_widget.value,\n",
        "    'batch_size': batch_size_widget.value,\n",
        "    'img_size': img_size_widget.value,\n",
        "    'model_size': model_widget.value,\n",
        "    'optimizer': optimizer_widget.value,\n",
        "    'device': device_widget.value if device_widget.value != 'auto' else '',\n",
        "    'patience': patience_widget.value,\n",
        "    'lr0': lr0_widget.value\n",
        "})\n",
        "\n",
        "print(\"Updated training configuration:\")\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Load model with updated configuration\n",
        "if TRAINING_CONFIG['model_size'] != model.model_name if hasattr(model, 'model_name') else '':\n",
        "    print(f\"\\nLoading new model: {TRAINING_CONFIG['model_size']}\")\n",
        "    model = load_model(TRAINING_CONFIG['model_size'])\n",
        "\n",
        "# Confirm before starting training\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"READY TO START TRAINING\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Dataset: {DATA_CONFIG}\")\n",
        "print(f\"Model: {TRAINING_CONFIG['model_size']}\")\n",
        "print(f\"Epochs: {TRAINING_CONFIG['epochs']}\")\n",
        "print(f\"Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
        "print(f\"Image size: {TRAINING_CONFIG['img_size']}\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training (uncomment to run)\n",
        "# WARNING: This will start training - make sure your configuration is correct!\n",
        "\n",
        "# results, log_file = train_model(model, TRAINING_CONFIG, DATA_CONFIG)\n",
        "# print(f\"Training completed! Log file: {log_file}\")\n",
        "\n",
        "print(\"Uncomment the lines above to start training!\")\n",
        "print(\"Make sure your configuration is correct before starting.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Training Monitoring and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_results(results_dir):\n",
        "    \"\"\"Plot training results from results directory.\"\"\"\n",
        "    results_dir = Path(results_dir)\n",
        "    \n",
        "    # Look for results.png or results.csv\n",
        "    results_png = results_dir / 'results.png'\n",
        "    results_csv = results_dir / 'results.csv'\n",
        "    \n",
        "    if results_png.exists():\n",
        "        print(\"Training Results:\")\n",
        "        display(Image(str(results_png)))\n",
        "    \n",
        "    if results_csv.exists():\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(results_csv)\n",
        "        print(\"\\nTraining Metrics:\")\n",
        "        print(df.tail(10))  # Show last 10 epochs\n",
        "        \n",
        "        # Plot key metrics\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        # Plot losses\n",
        "        if 'train/box_loss' in df.columns:\n",
        "            axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Box Loss')\n",
        "            axes[0, 0].plot(df['epoch'], df['train/cls_loss'], label='Class Loss')\n",
        "            axes[0, 0].plot(df['epoch'], df['train/dfl_loss'], label='DFL Loss')\n",
        "            axes[0, 0].set_title('Training Losses')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True)\n",
        "        \n",
        "        # Plot mAP\n",
        "        if 'metrics/mAP50(B)' in df.columns:\n",
        "            axes[0, 1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5')\n",
        "            axes[0, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95')\n",
        "            axes[0, 1].set_title('Validation mAP')\n",
        "            axes[0, 1].legend()\n",
        "            axes[0, 1].grid(True)\n",
        "        \n",
        "        # Plot precision and recall\n",
        "        if 'metrics/precision(B)' in df.columns:\n",
        "            axes[1, 0].plot(df['epoch'], df['metrics/precision(B)'], label='Precision')\n",
        "            axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'], label='Recall')\n",
        "            axes[1, 0].set_title('Precision & Recall')\n",
        "            axes[1, 0].legend()\n",
        "            axes[1, 0].grid(True)\n",
        "        \n",
        "        # Plot learning rate\n",
        "        if 'lr/pg0' in df.columns:\n",
        "            axes[1, 1].plot(df['epoch'], df['lr/pg0'], label='Learning Rate')\n",
        "            axes[1, 1].set_title('Learning Rate')\n",
        "            axes[1, 1].legend()\n",
        "            axes[1, 1].grid(True)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example usage (uncomment and adjust path)\n",
        "# results_dir = 'runs/train/yolo11_infrared'\n",
        "# plot_training_results(results_dir)\n",
        "\n",
        "print(\"Training monitoring functions ready!\")\n",
        "print(\"Use plot_training_results('path/to/results') to visualize training progress.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 9. Model Validation and Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_model(model_path, data_config, img_size=640):\n",
        "    \"\"\"Validate trained model.\"\"\"\n",
        "    model = YOLO(model_path)\n",
        "    \n",
        "    print(f\"Validating model: {model_path}\")\n",
        "    print(f\"Dataset: {data_config}\")\n",
        "    \n",
        "    # Run validation\n",
        "    results = model.val(\n",
        "        data=data_config,\n",
        "        imgsz=img_size,\n",
        "        save_json=True,\n",
        "        save_hybrid=True,\n",
        "        plots=True\n",
        "    )\n",
        "    \n",
        "    print(\"\\nValidation Results:\")\n",
        "    print(f\"mAP@0.5: {results.box.map50:.4f}\")\n",
        "    print(f\"mAP@0.5:0.95: {results.box.map:.4f}\")\n",
        "    print(f\"Precision: {results.box.mp:.4f}\")\n",
        "    print(f\"Recall: {results.box.mr:.4f}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "def test_inference(model_path, image_path, conf_threshold=0.25):\n",
        "    \"\"\"Test model inference on a single image.\"\"\"\n",
        "    model = YOLO(model_path)\n",
        "    \n",
        "    # Run inference\n",
        "    results = model(image_path, conf=conf_threshold)\n",
        "    \n",
        "    # Display results\n",
        "    for r in results:\n",
        "        # Plot results\n",
        "        im_array = r.plot()\n",
        "        \n",
        "        # Convert BGR to RGB for matplotlib\n",
        "        im_array = im_array[:, :, ::-1]\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(im_array)\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Inference Results - Confidence: {conf_threshold}')\n",
        "        plt.show()\n",
        "        \n",
        "        # Print detection info\n",
        "        if r.boxes is not None:\n",
        "            print(f\"Detections: {len(r.boxes)}\")\n",
        "            for i, box in enumerate(r.boxes):\n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                print(f\"  {i+1}: Class {cls} ({model.names[cls]}) - Confidence: {conf:.3f}\")\n",
        "        else:\n",
        "            print(\"No detections found\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "print(\"Validation functions ready!\")\n",
        "print(\"Use validate_model() and test_inference() to test your trained model.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 10. Model Export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_model(model_path, export_formats=['onnx'], img_size=640):\n",
        "    \"\"\"Export trained model to different formats.\"\"\"\n",
        "    model = YOLO(model_path)\n",
        "    \n",
        "    print(f\"Exporting model: {model_path}\")\n",
        "    \n",
        "    exported_models = {}\n",
        "    \n",
        "    for fmt in export_formats:\n",
        "        try:\n",
        "            print(f\"Exporting to {fmt.upper()}...\")\n",
        "            exported_path = model.export(\n",
        "                format=fmt,\n",
        "                imgsz=img_size,\n",
        "                optimize=True,\n",
        "                half=False\n",
        "            )\n",
        "            exported_models[fmt] = exported_path\n",
        "            print(f\"  ✓ Exported to: {exported_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Failed to export to {fmt}: {e}\")\n",
        "    \n",
        "    return exported_models\n",
        "\n",
        "# Available export formats\n",
        "EXPORT_FORMATS = [\n",
        "    'onnx',      # ONNX\n",
        "    'torchscript', # TorchScript\n",
        "    'tensorflow', # TensorFlow\n",
        "    'tflite',    # TensorFlow Lite\n",
        "    'edgetpu',   # Edge TPU\n",
        "    'openvino',  # OpenVINO\n",
        "    'coreml',    # CoreML\n",
        "    'tensorrt'   # TensorRT\n",
        "]\n",
        "\n",
        "print(\"Export functions ready!\")\n",
        "print(f\"Available formats: {EXPORT_FORMATS}\")\n",
        "print(\"Use export_model() to convert your trained model.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 11. Quick Start Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick start examples - uncomment to use\n",
        "\n",
        "# Example 1: Validate a trained model\n",
        "# model_path = 'runs/train/yolo11_infrared/weights/best.pt'\n",
        "# results = validate_model(model_path, DATA_CONFIG)\n",
        "\n",
        "# Example 2: Test inference on an image\n",
        "# test_image = 'datasets/infrared/images/val/1.jpg'\n",
        "# inference_results = test_inference(model_path, test_image, conf_threshold=0.5)\n",
        "\n",
        "# Example 3: Export model to ONNX\n",
        "# exported = export_model(model_path, ['onnx'], img_size=640)\n",
        "\n",
        "# Example 4: Plot training results\n",
        "# plot_training_results('runs/train/yolo11_infrared')\n",
        "\n",
        "print(\"Quick start examples ready!\")\n",
        "print(\"Uncomment the examples above to use them.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 12. Utilities and System Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def list_available_models():\n",
        "    \"\"\"List available YOLO11 models.\"\"\"\n",
        "    models = {\n",
        "        'yolo11n.pt': 'Nano - Fastest, smallest model',\n",
        "        'yolo11s.pt': 'Small - Good balance of speed and accuracy',\n",
        "        'yolo11m.pt': 'Medium - Better accuracy, slower',\n",
        "        'yolo11l.pt': 'Large - High accuracy, slower',\n",
        "        'yolo11x.pt': 'Extra Large - Highest accuracy, slowest'\n",
        "    }\n",
        "    \n",
        "    print(\"Available YOLO11 models:\")\n",
        "    for model, description in models.items():\n",
        "        print(f\"  {model}: {description}\")\n",
        "    \n",
        "    return models\n",
        "\n",
        "def check_dataset_integrity(dataset_config_path):\n",
        "    \"\"\"Check dataset integrity and statistics.\"\"\"\n",
        "    config = load_dataset_config(dataset_config_path)\n",
        "    dataset_path = Path(config['path'])\n",
        "    \n",
        "    print(\"Dataset Integrity Check:\")\n",
        "    print(f\"Dataset path: {dataset_path}\")\n",
        "    \n",
        "    # Check directories\n",
        "    train_img_dir = dataset_path / config['train']\n",
        "    val_img_dir = dataset_path / config['val']\n",
        "    train_lbl_dir = dataset_path / 'labels' / 'train'\n",
        "    val_lbl_dir = dataset_path / 'labels' / 'val'\n",
        "    \n",
        "    dirs_to_check = {\n",
        "        'Train images': train_img_dir,\n",
        "        'Val images': val_img_dir,\n",
        "        'Train labels': train_lbl_dir,\n",
        "        'Val labels': val_lbl_dir\n",
        "    }\n",
        "    \n",
        "    for name, path in dirs_to_check.items():\n",
        "        if path.exists():\n",
        "            count = len(list(path.glob('*')))\n",
        "            print(f\"  ✓ {name}: {count} files\")\n",
        "        else:\n",
        "            print(f\"  ✗ {name}: Directory not found\")\n",
        "    \n",
        "    return config\n",
        "\n",
        "def get_system_info():\n",
        "    \"\"\"Get system information for debugging.\"\"\"\n",
        "    info = {\n",
        "        'Python version': sys.version,\n",
        "        'PyTorch version': torch.__version__,\n",
        "        'CUDA available': torch.cuda.is_available(),\n",
        "        'GPU count': torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
        "    }\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        info['GPU name'] = torch.cuda.get_device_name(0)\n",
        "        info['CUDA version'] = torch.version.cuda\n",
        "        info['GPU memory'] = f\"{torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\"\n",
        "    \n",
        "    print(\"System Information:\")\n",
        "    for key, value in info.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    \n",
        "    return info\n",
        "\n",
        "# Run utility functions\n",
        "list_available_models()\n",
        "print()\n",
        "get_system_info()\n",
        "print()\n",
        "if DATA_CONFIG.exists():\n",
        "    check_dataset_integrity(DATA_CONFIG)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
